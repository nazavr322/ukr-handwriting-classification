{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae7883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nazar/Projects/ukrainian_handwriting\n",
      "/home/nazar/Projects/ukrainian_handwriting/notebooks\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import numpy as np\n",
    "%cd ../\n",
    "from src.data.datasets import HandwritingDataset\n",
    "from src.models import HandwritingClassifier\n",
    "%cd notebooks/\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b608f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0789b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = HandwritingClassifier._mean\n",
    "STD = HandwritingClassifier._std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85932b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = T.Compose([\n",
    "    T.RandomRotation(30),\n",
    "    T.RandomAffine(0, (0.1, 0.1)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=MEAN, std=STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607759a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training data: 1281\n",
      "Number of samples in test data: 300\n"
     ]
    }
   ],
   "source": [
    "train_data = HandwritingDataset(\n",
    "    '../data/processed/train_data.csv',\n",
    "    transforms=tf\n",
    ")\n",
    "\n",
    "test_data = HandwritingDataset(\n",
    "    '../data/processed/test_data.csv',\n",
    "    transforms=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    ")\n",
    "\n",
    "print('Number of samples in training data:', len(train_data))\n",
    "print('Number of samples in test data:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8235c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VAL_SIZE = 100\n",
    "\n",
    "indices = list(range(len(train_data)))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[VAL_SIZE:], indices[:VAL_SIZE]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(train_data, sampler=val_sampler)\n",
    "test_loader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adab0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params: dict):\n",
    "    model = HandwritingClassifier()\n",
    "    model.load_state_dict(torch.load('../models/mnist_model.pt'))\n",
    "    \n",
    "    num_features = model.class_fc.in_features\n",
    "    model.class_fc = nn.Linear(num_features, 43)\n",
    "    \n",
    "    model.type(torch.cuda.FloatTensor)\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    LR = params['learning_rate']\n",
    "    REG = params['weight_decay']\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=REG)\n",
    "    \n",
    "    factor = params['factor']\n",
    "    patience = params['patience']\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor,\n",
    "                                                     patience=patience)\n",
    "    return model, criterion, optimizer, scheduler\n",
    "\n",
    "def train_model(params: dict):\n",
    "    model, criterion, optimizer, scheduler = build_model(params)\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        \n",
    "        for i, (x, y, _) in enumerate(train_loader):\n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            \n",
    "            loss_value = criterion(model(x_gpu), y_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        loss_acum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        model.eval()\n",
    "        for i, (x, y, _) in enumerate(val_loader):\n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            \n",
    "            logits = model(x_gpu)\n",
    "            loss_acum += criterion(logits, y_gpu).item()\n",
    "            prediction = torch.argmax(logits, 1)\n",
    "            \n",
    "            correct_samples += torch.sum(prediction == y_gpu).item()\n",
    "            total_samples += y.shape[0]\n",
    "        if scheduler:\n",
    "            scheduler.step(loss_acum / i)\n",
    "        accuracy = correct_samples / total_samples\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_epochs': trial.suggest_int('num_epochs', 30, 30),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ('SGD',)),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 7e-3, 7e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-3, 7e-3, log=True),\n",
    "        'scheduler': trial.suggest_categorical('scheduler', ('ReduceLROnPlateau',)),\n",
    "        'factor': trial.suggest_float('factor', 0.05, 0.2),\n",
    "        'patience': trial.suggest_int('patience', 2, 4),\n",
    "    }\n",
    "    \n",
    "    accuracy = train_model(params)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "512eb905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 19:10:21,757]\u001b[0m A new study created in memory with name: Test run for mnist + glyphs\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:11:11,388]\u001b[0m Trial 0 finished with value: 0.76 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.02065462907105721, 'weight_decay': 0.0020828018319538504, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.18435994273331363, 'patience': 2}. Best is trial 0 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:12:01,763]\u001b[0m Trial 1 finished with value: 0.76 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.018676047229254967, 'weight_decay': 0.003245110318934138, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.18442744604372996, 'patience': 3}. Best is trial 0 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:12:55,078]\u001b[0m Trial 2 finished with value: 0.79 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.04564540644369428, 'weight_decay': 0.002689645232801303, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.19242696080728677, 'patience': 4}. Best is trial 2 with value: 0.79.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:13:51,135]\u001b[0m Trial 3 finished with value: 0.75 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.013213150506671784, 'weight_decay': 0.0011916996940243426, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.13598549256969866, 'patience': 3}. Best is trial 2 with value: 0.79.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:14:42,923]\u001b[0m Trial 4 finished with value: 0.76 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.037285129289451595, 'weight_decay': 0.006979118845733176, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.09623281805042885, 'patience': 4}. Best is trial 2 with value: 0.79.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:15:35,948]\u001b[0m Trial 5 finished with value: 0.82 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.05900607950552754, 'weight_decay': 0.003388141752227381, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.07205950936236957, 'patience': 4}. Best is trial 5 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:16:27,790]\u001b[0m Trial 6 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.06568777127741031, 'weight_decay': 0.003281146888503395, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.06448200728535212, 'patience': 3}. Best is trial 5 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:17:28,128]\u001b[0m Trial 7 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.03258006161237433, 'weight_decay': 0.001167518148197354, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.19953120419908382, 'patience': 4}. Best is trial 5 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:18:20,415]\u001b[0m Trial 8 finished with value: 0.71 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.010500001674849197, 'weight_decay': 0.003956016042915209, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.08247479371193292, 'patience': 4}. Best is trial 5 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:19:08,803]\u001b[0m Trial 9 finished with value: 0.76 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.009624661437830872, 'weight_decay': 0.001631637666826178, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.19346104516901874, 'patience': 4}. Best is trial 5 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:19:57,471]\u001b[0m Trial 10 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.0635231950855179, 'weight_decay': 0.00519025033372524, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.05139067065921209, 'patience': 2}. Best is trial 5 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:20:43,183]\u001b[0m Trial 11 finished with value: 0.82 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.04071595516722889, 'weight_decay': 0.002500668665273593, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1448300280801394, 'patience': 4}. Best is trial 5 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:21:28,981]\u001b[0m Trial 12 finished with value: 0.7 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.04537448427721342, 'weight_decay': 0.002075989679562933, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.14158776793763875, 'patience': 4}. Best is trial 5 with value: 0.82.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:22:14,778]\u001b[0m Trial 13 finished with value: 0.85 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.02880888755080388, 'weight_decay': 0.004148667900144795, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.11183605527517573, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:23:00,442]\u001b[0m Trial 14 finished with value: 0.76 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.029266450628793406, 'weight_decay': 0.004433510876230307, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.11625446843758294, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:23:46,268]\u001b[0m Trial 15 finished with value: 0.78 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.026172770230211632, 'weight_decay': 0.005972448815647611, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.10597846753334642, 'patience': 2}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:24:31,906]\u001b[0m Trial 16 finished with value: 0.73 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.015900732024055217, 'weight_decay': 0.003586812829470498, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.08225594276558791, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:25:17,362]\u001b[0m Trial 17 finished with value: 0.71 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.007617091968547936, 'weight_decay': 0.004785105212418851, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.08187095513312563, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:26:05,769]\u001b[0m Trial 18 finished with value: 0.72 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.05500894784777323, 'weight_decay': 0.0029081155637190556, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.12009662182101327, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:26:51,218]\u001b[0m Trial 19 finished with value: 0.76 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.0257344913793602, 'weight_decay': 0.004163743841963097, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.16748257325389718, 'patience': 2}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:27:36,747]\u001b[0m Trial 20 finished with value: 0.73 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.05220912969234081, 'weight_decay': 0.005641487051493116, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.06043686120843597, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:28:22,114]\u001b[0m Trial 21 finished with value: 0.8 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.03623869806130984, 'weight_decay': 0.0020939176969642322, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.15802449735274313, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:29:07,804]\u001b[0m Trial 22 finished with value: 0.82 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.04129405130003045, 'weight_decay': 0.002380339513037898, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.150434148687496, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:29:53,157]\u001b[0m Trial 23 finished with value: 0.78 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.0531492073405241, 'weight_decay': 0.001520452394822306, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.13183589371164334, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:30:38,453]\u001b[0m Trial 24 finished with value: 0.81 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.06915739735832922, 'weight_decay': 0.002475331858813251, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.10139874951752965, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:31:24,039]\u001b[0m Trial 25 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.03077714449640294, 'weight_decay': 0.0037689967472842078, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.14896026776916638, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-18 19:32:09,445]\u001b[0m Trial 26 finished with value: 0.67 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.024954639877389183, 'weight_decay': 0.0030101471337972505, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.16544544868244854, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:32:54,893]\u001b[0m Trial 27 finished with value: 0.81 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.041914495323878115, 'weight_decay': 0.0016577512760907217, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1107172553115156, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:33:40,610]\u001b[0m Trial 28 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.03901074399753764, 'weight_decay': 0.0023984748389947108, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1287751753633695, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:34:25,920]\u001b[0m Trial 29 finished with value: 0.79 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.05494165579965548, 'weight_decay': 0.0020790834676894226, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.09227854747694653, 'patience': 2}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:35:11,388]\u001b[0m Trial 30 finished with value: 0.7 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.02048954948503338, 'weight_decay': 0.0034030215355342584, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.07033957007843085, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:35:56,939]\u001b[0m Trial 31 finished with value: 0.8 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.034570280723668065, 'weight_decay': 0.0022886638587030347, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1561479114992798, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:36:42,519]\u001b[0m Trial 32 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.046631969952864415, 'weight_decay': 0.0027992752119319663, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1753512626366895, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:37:28,016]\u001b[0m Trial 33 finished with value: 0.84 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.0435908221461567, 'weight_decay': 0.003040453087360256, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.15085725264502062, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:38:13,642]\u001b[0m Trial 34 finished with value: 0.75 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.02237499784412085, 'weight_decay': 0.001838679313727816, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1453597168827372, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:38:59,591]\u001b[0m Trial 35 finished with value: 0.79 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.04707034380470457, 'weight_decay': 0.0031398443135799542, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1792181063351271, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:39:47,245]\u001b[0m Trial 36 finished with value: 0.78 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.05915211261740462, 'weight_decay': 0.002650472841115032, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1374379972554902, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:40:39,310]\u001b[0m Trial 37 finished with value: 0.83 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.017475378819703007, 'weight_decay': 0.004458485781854614, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.12332401505470883, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:41:26,126]\u001b[0m Trial 38 finished with value: 0.75 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.017113729921214994, 'weight_decay': 0.004078675820296616, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.12000833901830295, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:42:12,949]\u001b[0m Trial 39 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.013769155181739406, 'weight_decay': 0.006393294186127549, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.12356115547444799, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:42:58,440]\u001b[0m Trial 40 finished with value: 0.73 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.01956954588651714, 'weight_decay': 0.00468906555905599, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.13164527884647276, 'patience': 3}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:43:43,917]\u001b[0m Trial 41 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.027970495882973578, 'weight_decay': 0.003549131264838046, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.15506552496227247, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:44:31,150]\u001b[0m Trial 42 finished with value: 0.78 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.03267898633273897, 'weight_decay': 0.0010189659841269895, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1390532977549646, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:45:16,949]\u001b[0m Trial 43 finished with value: 0.73 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.01208366905258941, 'weight_decay': 0.005132702324879143, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1132374695728605, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:46:02,535]\u001b[0m Trial 44 finished with value: 0.76 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.017792451342322647, 'weight_decay': 0.003345268176652214, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.0955619941423543, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:46:47,950]\u001b[0m Trial 45 finished with value: 0.8 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.039146757267798205, 'weight_decay': 0.0025771626649583033, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1675349999835797, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:47:33,639]\u001b[0m Trial 46 finished with value: 0.75 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.022337391393153504, 'weight_decay': 0.004448417040093762, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.07249202845609824, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:48:19,762]\u001b[0m Trial 47 finished with value: 0.84 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.04421493480991065, 'weight_decay': 0.002220337688906879, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.14955495283005102, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:49:05,180]\u001b[0m Trial 48 finished with value: 0.72 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.06283376674955575, 'weight_decay': 0.003802117949111549, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.10301216913194448, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n",
      "\u001b[32m[I 2022-07-18 19:49:51,323]\u001b[0m Trial 49 finished with value: 0.77 and parameters: {'num_epochs': 30, 'optimizer': 'SGD', 'learning_rate': 0.04389860291917251, 'weight_decay': 0.0022364467510196306, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.15102874469830074, 'patience': 4}. Best is trial 13 with value: 0.85.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "name = 'Test run for mnist + glyphs'\n",
    "study = optuna.create_study(study_name=name, direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce4b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f281cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/best_params.json', 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
