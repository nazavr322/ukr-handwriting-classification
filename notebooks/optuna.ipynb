{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f90fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nazar/Projects/ukrainian_handwriting\n",
      "/home/nazar/Projects/ukrainian_handwriting/notebooks\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%cd ../\n",
    "from src.data.datasets import HandwritingDataset\n",
    "from src.models.models import HandwritingClassifier\n",
    "%cd notebooks/\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0c9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bac53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = HandwritingClassifier._mean\n",
    "STD = HandwritingClassifier._std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240d8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = T.Compose([\n",
    "    T.RandomRotation(30),\n",
    "    T.RandomAffine(0, (0.1, 0.1)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=MEAN, std=STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ed963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training data: 1281\n",
      "Number of samples in test data: 300\n"
     ]
    }
   ],
   "source": [
    "train_data = HandwritingDataset(\n",
    "    '../data/processed/train_data.csv',\n",
    "    transforms=tf\n",
    ")\n",
    "\n",
    "test_data = HandwritingDataset(\n",
    "    '../data/processed/test_data.csv',\n",
    "    transforms=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    ")\n",
    "\n",
    "print('Number of samples in training data:', len(train_data))\n",
    "print('Number of samples in test data:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fddfadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VAL_SIZE = 100\n",
    "\n",
    "indices = list(range(len(train_data)))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[VAL_SIZE:], indices[:VAL_SIZE]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(train_data, sampler=val_sampler)\n",
    "test_loader = DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2751baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params: dict):\n",
    "#     model = HandwritingClassifier()\n",
    "#     model.load_state_dict(torch.load('../models/mnist_model.pt'), strict=False)\n",
    "    \n",
    "#     # freeze pretrained model\n",
    "#     for fname, param in model.named_parameters():\n",
    "#         name = fname.split('.')[0]\n",
    "#         if name == 'token_classifier' or name == 'is_upp_classifier':\n",
    "#             continue\n",
    "#         param.requires_grad = False\n",
    "\n",
    "\n",
    "    model = torch.load('../models/model_heads.pth')\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion_1 = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "    criterion_2 = nn.BCEWithLogitsLoss().type(torch.cuda.FloatTensor)\n",
    "    losses = (criterion_1, criterion_2)\n",
    "    \n",
    "    LR = params['learning_rate']\n",
    "    REG = params['weight_decay']\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=REG)\n",
    "#     heads = chain(\n",
    "#             model.token_classifier.parameters(),\n",
    "#             model.is_upp_classifier.parameters()\n",
    "#         )\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=REG)\n",
    "    \n",
    "    \n",
    "    factor = params['factor']\n",
    "    patience = params['patience']\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor, patience=patience)\n",
    "    return model, losses, optimizer, scheduler\n",
    "\n",
    "\n",
    "def compute_accuracy(prediction, ground_truth):\n",
    "    correct = torch.sum(prediction == ground_truth).item()\n",
    "    return correct / len(ground_truth)\n",
    "\n",
    "\n",
    "def validate(model, losses, loader):\n",
    "    model.eval()\n",
    "    lbl_acc = 0\n",
    "    is_upp_acc = 0\n",
    "    loss_acum = 0\n",
    "    for i, (x, *y) in enumerate(loader):\n",
    "        x_gpu = x.to(device)\n",
    "        y[1] = y[1].unsqueeze(1).float()\n",
    "        y_gpu = tuple(targ.to(device) for targ in y)\n",
    "        \n",
    "        prediction = model(x_gpu)\n",
    "        loss_value = sum(\n",
    "            loss(out, targ) for loss, out, targ in zip(losses, prediction, y_gpu)\n",
    "        )\n",
    "        \n",
    "        loss_acum += loss_value.item()\n",
    "        lbl = torch.argmax(prediction[0], 1)\n",
    "        lbl_acc += compute_accuracy(lbl, y_gpu[0])\n",
    "        is_upp = 0 if prediction[1].item() < 0.5 else 1\n",
    "        is_upp_acc += compute_accuracy(is_upp, y_gpu[1])\n",
    "    return loss_acum / i, lbl_acc / i, is_upp_acc / i\n",
    "\n",
    "def train_model(params: dict):\n",
    "    model, losses, optimizer, scheduler = build_model(params)\n",
    "    \n",
    "    num_epochs = params['num_epochs']\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for i, (x, *y) in enumerate(train_loader):\n",
    "            x_gpu = x.to(device)\n",
    "            y[1] = y[1].unsqueeze(1).float()\n",
    "            y_gpu = tuple(target.to(device) for target in y)\n",
    "            \n",
    "            prediction = model(x_gpu)\n",
    "            loss_value = sum(\n",
    "                loss(out, targ) for loss, out, targ in zip(losses, prediction, y_gpu)\n",
    "            )\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        val_loss, lbl_acc, is_upp_acc = validate(model, losses, val_loader)\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_epochs': trial.suggest_int('num_epochs', 20, 20),\n",
    "        'batch_size': trial.suggest_int('batch_size', 64, 64),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ('Adam',)),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 5e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-3, 1e-2, log=True),\n",
    "        'scheduler': trial.suggest_categorical('scheduler', ('ReduceLROnPlateau',)),\n",
    "        'factor': trial.suggest_float('factor', 0.1, 0.4),\n",
    "        'patience': trial.suggest_int('patience', 1, 3),\n",
    "    }\n",
    "    \n",
    "    val_loss = train_model(params)\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477a4fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-04 20:48:08,514]\u001b[0m A new study created in memory with name: Test run for mnist + glyphs and case determination\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:48:46,385]\u001b[0m Trial 0 finished with value: 0.6471148654571593 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.016374941470623364, 'weight_decay': 0.0021391377679174256, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.25915355413417274, 'patience': 1}. Best is trial 0 with value: 0.6471148654571593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:49:23,367]\u001b[0m Trial 1 finished with value: 0.7570399295802068 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.015107217937173891, 'weight_decay': 0.002335750989092541, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.214428481842945, 'patience': 3}. Best is trial 0 with value: 0.6471148654571593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:50:04,310]\u001b[0m Trial 2 finished with value: 0.7158659761207122 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0010165237416189666, 'weight_decay': 0.0035333265073349937, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.28017140550009945, 'patience': 1}. Best is trial 0 with value: 0.6471148654571593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:50:42,793]\u001b[0m Trial 3 finished with value: 0.7905866513405033 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.002484773475556418, 'weight_decay': 0.00514955955112598, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.20814446968959224, 'patience': 2}. Best is trial 0 with value: 0.6471148654571593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:51:17,012]\u001b[0m Trial 4 finished with value: 0.9365422426901683 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0486535544444342, 'weight_decay': 0.003670872388143859, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.24375724040580177, 'patience': 1}. Best is trial 0 with value: 0.6471148654571593.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:51:58,474]\u001b[0m Trial 5 finished with value: 0.6305975422658252 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.007728040400016092, 'weight_decay': 0.003581149400650326, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3165024057941809, 'patience': 2}. Best is trial 5 with value: 0.6305975422658252.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:52:41,234]\u001b[0m Trial 6 finished with value: 0.6004125699612566 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0014714575438120397, 'weight_decay': 0.0017252990181525587, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3182412092700824, 'patience': 3}. Best is trial 6 with value: 0.6004125699612566.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:53:21,805]\u001b[0m Trial 7 finished with value: 0.6353975217907003 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.00224887983675396, 'weight_decay': 0.0031907662167462497, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3126679485524384, 'patience': 3}. Best is trial 6 with value: 0.6004125699612566.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:53:57,807]\u001b[0m Trial 8 finished with value: 0.8141041674011509 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.018584710791119105, 'weight_decay': 0.001622184838171496, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.18010084661262887, 'patience': 1}. Best is trial 6 with value: 0.6004125699612566.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:54:36,175]\u001b[0m Trial 9 finished with value: 0.6084919345536919 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0043406481204433705, 'weight_decay': 0.0025992720596322394, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.27930658476357884, 'patience': 1}. Best is trial 6 with value: 0.6004125699612566.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:55:17,615]\u001b[0m Trial 10 finished with value: 0.6368223481077814 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.001061940186537445, 'weight_decay': 0.0010542959943819143, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.39703886010716394, 'patience': 3}. Best is trial 6 with value: 0.6004125699612566.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:55:59,703]\u001b[0m Trial 11 finished with value: 0.756988998286125 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0034135095580588633, 'weight_decay': 0.00864795148378982, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3611264540116127, 'patience': 2}. Best is trial 6 with value: 0.6004125699612566.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:56:39,739]\u001b[0m Trial 12 finished with value: 0.5680293142107654 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.004512436288134803, 'weight_decay': 0.0013126564625864066, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3267075178719204, 'patience': 3}. Best is trial 12 with value: 0.5680293142107654.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:57:15,842]\u001b[0m Trial 13 finished with value: 0.6070062702949713 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.006158222601384244, 'weight_decay': 0.00123916953155734, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1310712451310454, 'patience': 3}. Best is trial 12 with value: 0.5680293142107654.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:57:53,727]\u001b[0m Trial 14 finished with value: 0.453166622933085 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0018714261824103117, 'weight_decay': 0.0016080670614544168, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.34534851972755976, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:58:29,858]\u001b[0m Trial 15 finished with value: 0.5765078380807407 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0019696380055812942, 'weight_decay': 0.0014132862726481228, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3638128088887103, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:59:06,633]\u001b[0m Trial 16 finished with value: 0.5159381054064865 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.007240671201816052, 'weight_decay': 0.001022031649132907, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.35258919630056057, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 20:59:43,531]\u001b[0m Trial 17 finished with value: 0.5353283386123648 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.009111852942657804, 'weight_decay': 0.0010103432856453055, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3930870181829193, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:00:22,899]\u001b[0m Trial 18 finished with value: 1.0176987236299826 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.033325469762068044, 'weight_decay': 0.0018387481453347912, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.34306727879442234, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:00:58,902]\u001b[0m Trial 19 finished with value: 0.7063433806120296 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.008618779038567437, 'weight_decay': 0.005115377661343143, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.10239314606037841, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:01:34,040]\u001b[0m Trial 20 finished with value: 0.5467533346282017 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.012116705523351718, 'weight_decay': 0.001231592851881364, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3695942554572791, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:02:10,665]\u001b[0m Trial 21 finished with value: 0.583817497996444 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.005621707410226217, 'weight_decay': 0.001106452657527389, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3835455815228281, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-04 21:02:42,679]\u001b[0m Trial 22 finished with value: 0.8073664940534997 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.009839860488035337, 'weight_decay': 0.001013802807943777, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3924330960863711, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:03:19,402]\u001b[0m Trial 23 finished with value: 0.8966747745965616 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.02444581786501235, 'weight_decay': 0.0014929762711947765, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.34496775477011066, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:03:56,231]\u001b[0m Trial 24 finished with value: 0.48420781971218835 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0035701854265127505, 'weight_decay': 0.0019369326744404184, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.28945039038174336, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:04:33,634]\u001b[0m Trial 25 finished with value: 0.6338700027466102 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.003147190258089206, 'weight_decay': 0.0019810763185106476, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.29057981859836923, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:05:07,403]\u001b[0m Trial 26 finished with value: 0.4844303085489876 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.00148957305872603, 'weight_decay': 0.002462707800349855, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.2944258124816186, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:05:42,140]\u001b[0m Trial 27 finished with value: 0.5616518153216351 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0017223816169158826, 'weight_decay': 0.002659830386917987, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.25109856724600377, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:06:15,624]\u001b[0m Trial 28 finished with value: 0.7111423527057555 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0014236598284179743, 'weight_decay': 0.002728011372227053, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.29485565396375574, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:06:49,221]\u001b[0m Trial 29 finished with value: 0.5780517940146077 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0027903289734653473, 'weight_decay': 0.0022279427396437322, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.26300527864151363, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:07:27,644]\u001b[0m Trial 30 finished with value: 0.614561428616971 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.001364062260345972, 'weight_decay': 0.004367280152411947, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.23009278179123327, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:08:05,653]\u001b[0m Trial 31 finished with value: 0.47597518583731446 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0041961889344593155, 'weight_decay': 0.002024864488470329, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3430910821447089, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:08:41,559]\u001b[0m Trial 32 finished with value: 0.5677390743465623 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.00423306423359208, 'weight_decay': 0.002110424556274838, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.29684501502065824, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:09:18,556]\u001b[0m Trial 33 finished with value: 0.5040545866253193 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0019740144568093205, 'weight_decay': 0.00245440859588405, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3331250026474656, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:09:59,219]\u001b[0m Trial 34 finished with value: 0.573283692787171 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.003567836082894813, 'weight_decay': 0.0019370442722221033, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.2754710632403153, 'patience': 1}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:10:34,974]\u001b[0m Trial 35 finished with value: 0.5196731169871232 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0023797090021499814, 'weight_decay': 0.0016293524430622101, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3101191795923404, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:11:12,122]\u001b[0m Trial 36 finished with value: 0.6602106746568372 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0012124920258057852, 'weight_decay': 0.0031904345078451494, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.2643415962932978, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:11:52,432]\u001b[0m Trial 37 finished with value: 0.7596016999221209 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0017598251208733858, 'weight_decay': 0.0021913058264766095, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.1973059239084181, 'patience': 2}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:12:28,908]\u001b[0m Trial 38 finished with value: 0.6508206163834066 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0030617058783617432, 'weight_decay': 0.0018129434987893423, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3029940358971133, 'patience': 1}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:13:03,450]\u001b[0m Trial 39 finished with value: 0.6063324923467155 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0054203248447278135, 'weight_decay': 0.007324737567836533, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.23563856680047607, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:13:37,885]\u001b[0m Trial 40 finished with value: 0.4909700312171922 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0025486332897487786, 'weight_decay': 0.0015572352181068008, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.32760917907414827, 'patience': 3}. Best is trial 14 with value: 0.453166622933085.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:14:13,611]\u001b[0m Trial 41 finished with value: 0.4180572386642899 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0023955033226241208, 'weight_decay': 0.001516250075936066, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3278769074801458, 'patience': 3}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:14:50,533]\u001b[0m Trial 42 finished with value: 0.7241238185235139 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0021722463239485157, 'weight_decay': 0.0029652468146574595, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3374334626939279, 'patience': 3}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:15:27,314]\u001b[0m Trial 43 finished with value: 0.6032704778975158 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0016710702442764768, 'weight_decay': 0.002357742412253268, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.37645694509693367, 'patience': 3}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:16:02,882]\u001b[0m Trial 44 finished with value: 0.4941945467614616 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.004408361717696598, 'weight_decay': 0.0014148680673983843, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.31901139676697515, 'patience': 3}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-04 21:16:38,434]\u001b[0m Trial 45 finished with value: 0.5545093628173374 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.001086133044674393, 'weight_decay': 0.001711591925069332, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.2805706286082292, 'patience': 2}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:17:16,233]\u001b[0m Trial 46 finished with value: 0.5975347953340546 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0038915943569137255, 'weight_decay': 0.003848222894273991, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.35339981110607294, 'patience': 3}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:17:52,813]\u001b[0m Trial 47 finished with value: 0.4731298969515289 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.002453734949863882, 'weight_decay': 0.0020321339555709897, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.3148174756379504, 'patience': 3}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:18:32,676]\u001b[0m Trial 48 finished with value: 0.5924427933577034 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.002689485815282177, 'weight_decay': 0.002024641631238774, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.32013315345748916, 'patience': 1}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n",
      "\u001b[32m[I 2022-09-04 21:19:08,460]\u001b[0m Trial 49 finished with value: 0.5073545564887951 and parameters: {'num_epochs': 20, 'batch_size': 64, 'optimizer': 'Adam', 'learning_rate': 0.0050255719338387125, 'weight_decay': 0.0011804014837946976, 'scheduler': 'ReduceLROnPlateau', 'factor': 0.35775922886533074, 'patience': 2}. Best is trial 41 with value: 0.4180572386642899.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "name = 'Test run for mnist + glyphs and case determination'\n",
    "study = optuna.create_study(study_name=name)\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f2de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f876d7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_epochs': 20,\n",
       " 'batch_size': 64,\n",
       " 'optimizer': 'Adam',\n",
       " 'learning_rate': 0.0023955033226241208,\n",
       " 'weight_decay': 0.001516250075936066,\n",
       " 'scheduler': 'ReduceLROnPlateau',\n",
       " 'factor': 0.3278769074801458,\n",
       " 'patience': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c730275",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/new_best_params.json', 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
